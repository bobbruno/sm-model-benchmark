{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries to be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from shutil import copytree, rmtree\n",
    "from glob import glob\n",
    "import boto3\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOO_BUCKET = 'sagemaker-us-east-1-113147044314'\n",
    "ZOO_DIR = 'tf-model-zoo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to copy [Tensorflow Model Zoo](https://github.com/tensorflow/models) object detection models to S3 and creating SageMaker Model from them.\n",
    "\n",
    "SageMaker uses Tensorflow Serving, which requires the model to be in a folder structure like this:\n",
    "\n",
    "```\n",
    "model_dir/\n",
    "  |\n",
    "  +-version/\n",
    "       |\n",
    "       +-variables/\n",
    "       |\n",
    "       +-saved_model.pb\n",
    "```\n",
    "\n",
    "The models available in model zoo object detection are in a tar file, containing a folder structure in the following format:\n",
    "```\n",
    "model_dir/\n",
    "  |\n",
    "  +-<several files>\n",
    "  |\n",
    "  +-saved_model/\n",
    "      |\n",
    "      +-variables/\n",
    "      |\n",
    "      +-saved_model.pb\n",
    "```\n",
    "\n",
    "The `load_model_in_s3` function downloads the tar file from the zoo, unpacks it and takes the `saved_model` directory. It then restructures its content to the structure above, packs it into a `model.tar.gz` file which gets uploaded to the specified bucket and path, under a folder named after the model.\n",
    "\n",
    "The `download_and_create_model` function continues the process, calling `load_model_in_s3` and then creating a [`sagemker.tensorflow.serving.Model`](https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html#tensorflow-serving-model) object from the `model.tar.gz` file uploaded to s3. It can take additional parameters, which will be passed on to the `Model` initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_in_s3(model_name, s3_bucket=ZOO_BUCKET, s3_path=ZOO_DIR):\n",
    "    \"\"\"\n",
    "    Downloads an object detection model from Tensorflow Model Zoo, reorganizes the directory structure to be compatible with SageMaker and Tensorflow Serving\n",
    "    and copies it to the specified S3 location.\n",
    "    params:\n",
    "        **model_name**: exact name of the model as specified at https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\n",
    "        **s3_bucket**:  name of an S3 bucket where to store the repackaged model.tar.gz\n",
    "        **s3_path**:    path where to store the model.tar.gz inside the bucket. The model name will be appended to it as a folder, and the model.tar.gz will be uploaded to that destination.\n",
    "        \n",
    "    returns: the full S3 object path of the model.tar.gz file, with the format 's3://<s3_bucket>/<s3_path>/<model_name>/model.tar.gz'\n",
    "    \"\"\"\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    cache_dir='/tmp',\n",
    "    untar=True)\n",
    "\n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "    rmtree(f'/tmp/sm-models/{model_name}', ignore_errors=True)\n",
    "    copytree(model_dir.absolute().as_posix(), f'/tmp/sm-models/{model_name}/1')\n",
    "    cur_dir = os.getcwd()\n",
    "    os.chdir(f'/tmp/sm-models/{model_name}')\n",
    "    with tarfile.open(f\"../{model_name}.tar.gz\", \"w:gz\") as tar:\n",
    "        for name in glob('*'):\n",
    "            tar.add(name)\n",
    "    os.chdir(cur_dir)\n",
    "            \n",
    "    s3 = boto3.client('s3')\n",
    "    s3.upload_file(f\"/tmp/sm-models/{model_name}.tar.gz\", Bucket=s3_bucket, Key=f'{s3_path}/{model_name}/model.tar.gz')\n",
    "    return(f's3://{s3_bucket}/{s3_path}/{model_name}/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "import sagemaker\n",
    "import urllib\n",
    "\n",
    "def download_and_create_model(model_name, bucket=None, bucket_path='tf-model-zoo', role=None, **kwargs):\n",
    "    if bucket is None:\n",
    "        bucket = sagemaker.session.Session().default_bucket()\n",
    "    if role is None:\n",
    "        role=sagemaker.get_execution_role()\n",
    "    try:\n",
    "        model_tar = load_model_in_s3(model_name, bucket, bucket_path)\n",
    "    except urllib.error.HTTPError:\n",
    "        raise ValueError(f'Model {model_name} not found on Tensorflow Model Zoo.')\n",
    "    adj_model_name = model_name.replace(\"_\", \"-\").replace(\".\", \"-\")\n",
    "    model = Model(name=adj_model_name, model_data=model_tar, role=role, **kwargs)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions to Benchmark models on a directory of JPG images\n",
    "\n",
    "These functions simply execute inference and return the prediction from one or several images. For a more elaborate version that loads the categories and displays the image with bounding boxes and probabilities, please refer to the [Object detection API demo notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) in the Tensorflow Model Zoo repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These images are known to consistently cause some models to fail.\n",
    "\n",
    "bad_images = ['../data/000000001688.jpg',\n",
    "              '../data/000000002240.jpg',\n",
    "              '../data/000000000913.jpg',\n",
    "              '../data/000000004208.jpg',\n",
    "              '../data/000000000078.jpg',\n",
    "              '../data/000000000073.jpg',\n",
    "              '../data/000000002758.jpg',\n",
    "              '../data/000000003947.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_path, max_images=10, skip_images=None):\n",
    "    \"\"\"\n",
    "    Preloads an array of images from a path for faster inference\n",
    "    \"\"\"\n",
    "    if skip_images is None:\n",
    "        skip_images = []\n",
    "    images = [(im_file, np.array(Image.open(im_file))) \n",
    "              for im_file in glob(f'{image_path}/*.jpg')[:max_images] \n",
    "                  if im_file not in skip_images]\n",
    "    return(images)\n",
    "\n",
    "def predict_images(model, image_path, max_images=10, skip_images=None):\n",
    "    \"\"\"\n",
    "    does inference for a number of images from a path\n",
    "    \"\"\"\n",
    "    images = load_images(image_path, max_images, skip_images)\n",
    "    predictions = [(imfile, predict_image(model, image)) for imfile, image in images]\n",
    "    print([f\"{imfile} had no prediction\" for imfile, output in predictions if len(output) == 0])\n",
    "    return(predictions)\n",
    "\n",
    "def predict_image(model, image):\n",
    "    \"\"\"\n",
    "    Does inference for one preloaded image as a numpy array\n",
    "    \"\"\"\n",
    "    input_dict = {'instances': [image.tolist()]}\n",
    "    try:\n",
    "        output_dict = model.predict(input_dict)    \n",
    "    except Exception as e:\n",
    "        output_dict = {}\n",
    "        print(e)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a Model to SageMaker Tensorflow Serving\n",
    "\n",
    "Once deployed, the model expects a request with the following `body` structure:\n",
    "```\n",
    "input = {\n",
    "  'instances': [nested json list with all dimensions]\n",
    "}\n",
    "```\n",
    "\n",
    "This nested structured can be obtained by converting an array to a list object, for instance using the `numpy.ndarray.tolist()` method. The response is a JSON structure like this:\n",
    "```\n",
    "{\n",
    "  'predictions': [{'<prediction one>': [nested json array]}, {...},...]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark helper functions\n",
    "\n",
    "The functions below set up an inference endpoint, warm it up to reduce the impact of initial calls and profile the execution of a batch of images. They will be used for benchmarking models on several instance types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import cProfile\n",
    "import io\n",
    "import pstats\n",
    "from collections import namedtuple\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_predictor(predictor, n_times=500):\n",
    "    \"\"\"Warms up the predictor with a fixed image, to reduce the risk of erroneous performance measurements due to initializations and lazy loading.\"\"\"\n",
    "    x = np.array(Image.open('../data/000000004042.jpg'))\n",
    "    body={'instances':[x.tolist()]}\n",
    "    [predictor.predict(body) for _ in range(n_times)]\n",
    "    sleep(5000)\n",
    "    print(f'Warmup finished for {predictor.endpoint}.')\n",
    "\n",
    "\n",
    "def profile_predictor(predictor, images, executions=1):\n",
    "    \"\"\"Profiles the execution of a predictor with a batch of preloaded images.\"\"\"\n",
    "    pr = cProfile.Profile()\n",
    "    bodies = [{'instances':[x.tolist()]} for _, x in images]\n",
    "    pr.enable()\n",
    "    [predictor.predict(body) for _ in range(executions) for body in bodies]\n",
    "    pr.disable()\n",
    "    print(f'Profiling finished for {predictor.endpoint}.')\n",
    "    return(pr)\n",
    "\n",
    "\n",
    "def get_stats(profile, sort=['cumtime'], pct=.1):\n",
    "    \"\"\"Retrieves the profile statistics for a previous run, and returns the information in an object\n",
    "    returns:\n",
    "        Profile: a namedtuple containing:\n",
    "            - calls: integer total number of function calls made\n",
    "            - total_seconds: float measurement of the total execution time in seconds\n",
    "            - data: a Pandas DataFrame containing the details of individual calls, cumulative time, executions, etc.\n",
    "    \"\"\"\n",
    "    Profile = namedtuple('Profile', ['calls', 'total_seconds', 'data'])\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(profile, stream=s).sort_stats(*sort)\n",
    "    ps.print_stats(pct)\n",
    "    \n",
    "    headers = []\n",
    "    data = []\n",
    "    calls = None\n",
    "    total_seconds = None\n",
    "    for i, line in enumerate(s.getvalue().split(\"\\n\")):\n",
    "        if i == 0:\n",
    "            calls = re.match(r'\\s*(\\d+) function calls', line).groups(1)[0]\n",
    "            total_seconds = re.match(r\"in (\\d+\\.\\d+) seconds\", line)\n",
    "        if i < 5:\n",
    "            continue\n",
    "        reduced_line, _ = re.subn(\"\\s+\", \" \", line)\n",
    "        if len(reduced_line):\n",
    "            if reduced_line[0] == ' ':\n",
    "                reduced_line = reduced_line[1:]\n",
    "            cols = reduced_line.split(' ')\n",
    "            if headers and cols:\n",
    "                data.append({h: v for h, v in zip(headers, cols)})\n",
    "            if i == 5:\n",
    "                headers = cols\n",
    "    stats_data = pd.DataFrame(data)\n",
    "    return(Profile(calls, total_seconds, stats_data))\n",
    "\n",
    "\n",
    "def gen_model_instance_profile(model, instance, batch_size=100, executions=1):\n",
    "    \"\"\"Creates and profiles a predictor for the model and instance type requested.\n",
    "    params:\n",
    "        - model: name of the Tensorflow Model Zoo model to use\n",
    "        - instance: a string defining an acceptable instance type for hosting a SageMaker endpoint ('ml.<family>.<size>')\n",
    "        - images: a batch of images to run the benchmark on.\n",
    "        - executions: number of times the whole batch should be processed for profiling\n",
    "    returns ProfileResults: a namedtuple containing:\n",
    "            - model: the parameter described above\n",
    "            - instance_type: the `instance` parameter described above\n",
    "            - predictor: the sagemaker.Predictor created from the model and instance type passed. Its name is a combination of both.\n",
    "            - executions: the parameter described above\n",
    "            - calls: integer total number of function calls made\n",
    "            - total_seconds: float measurement of the total execution time in seconds\n",
    "            - data: a Pandas DataFrame containing the details of individual calls, cumulative time, executions, etc.\n",
    "    \"\"\"\n",
    "    print(f\"Starting profile for model {model} on {instance} with {batch_size} images...\")\n",
    "    model_instance = download_and_create_model(model, framework_version='2.1.0')\n",
    "    print(f'Created model {model_instance.name}')\n",
    "    \n",
    "    endpoint_name = f'{model_instance.name}-{instance.replace(\".\", \"-\")}'\n",
    "    predictor = model_instance.deploy(\n",
    "        initial_instance_count=1, instance_type=instance,\n",
    "        endpoint_name=endpoint_name,\n",
    "        update_endpoint=False)\n",
    "    print(f\"Endpoint {predictor.endpoint} created...\")\n",
    "    warmup_predictor(predictor)\n",
    "    \n",
    "    images = load_images(image_path='../data', max_images=batch_size, skip_images=bad_images)\n",
    "    ProfileResults = namedtuple('Profile', ['model', 'instance_type', 'predictor', 'executions', 'calls', 'total_seconds', 'data'])\n",
    "    profile = profile_predictor(predictor, images, executions=executions)\n",
    "    \n",
    "    stats = get_stats(profile)\n",
    "    return(ProfileResults(\n",
    "        model=model,\n",
    "        instance_type=instance,\n",
    "        predictor=predictor,\n",
    "        executions=executions,\n",
    "        calls=stats.calls,\n",
    "        total_seconds=stats.total_seconds,\n",
    "        data=stats.data\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark on the Prediction time for 100 images (images are from the COCO 2017 Validation Dataset)\n",
    "\n",
    "The benchmark will be run for several models and several instance types, as listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['faster_rcnn_resnet50_coco_2018_01_28', 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03', 'faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28']\n",
    "instance_types = ['ml.p3.2xlarge', 'ml.p2.xlarge', 'ml.c5.2xlarge', 'ml.c5.4xlarge', 'ml.m5.4xlarge']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below runs a parallel test of each model on all the instance types defined for benchmarking.\n",
    "\n",
    "**Note**: running all these instances in parallel incurs in costs and can reach service quota limits. Plan your own tests carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting profile for model faster_rcnn_resnet50_coco_2018_01_28 on ml.p2.xlarge with 100 images...\n",
      "Starting profile for model faster_rcnn_resnet50_coco_2018_01_28 on ml.p3.2xlarge with 100 images...\n",
      "Starting profile for model faster_rcnn_resnet50_coco_2018_01_28 on ml.c5.2xlarge with 100 images...\n",
      "Starting profile for model faster_rcnn_resnet50_coco_2018_01_28 on ml.c5.4xlarge with 100 images...\n",
      "Starting profile for model faster_rcnn_resnet50_coco_2018_01_28 on ml.m5.4xlarge with 100 images...\n",
      "Starting profile for model ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03 on ml.p3.2xlarge with 100 images...\n",
      "Created model faster-rcnn-resnet50-coco-2018-01-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: faster-rcnn-resnet50-coco-2018-01-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Created model faster-rcnn-resnet50-coco-2018-01-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: faster-rcnn-resnet50-coco-2018-01-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Created model ssd-resnet50-v1-fpn-shared-box-predictor-640x640-coco14-sync-2018-07-03\n",
      "Starting profile for model ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03 on ml.p2.xlarge with 100 images...\n",
      "Starting profile for model ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03 on ml.c5.2xlarge with 100 images...\n",
      "Starting profile for model ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03 on ml.c5.4xlarge with 100 images...\n",
      "Created model ssd-resnet50-v1-fpn-shared-box-predictor-640x640-coco14-sync-2018-07-03\n",
      "Starting profile for model ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03 on ml.m5.4xlarge with 100 images...\n",
      "Starting profile for model faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 on ml.p3.2xlarge with 100 images...\n",
      "Starting profile for model faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 on ml.p2.xlarge with 100 images...\n",
      "Created model ssd-resnet50-v1-fpn-shared-box-predictor-640x640-coco14-sync-2018-07-03\n",
      "Starting profile for model faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 on ml.c5.2xlarge with 100 images...\n",
      "--Created model faster-rcnn-inception-resnet-v2-atrous-coco-2018-01-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: faster-rcnn-inception-resnet-v2-atrous-coco-2018-01-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting profile for model faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 on ml.c5.4xlarge with 100 images...\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def parallel_gen(*params):\n",
    "    return(gen_model_instance_profile(params[0][0], params[0][1]))\n",
    "\n",
    "with Pool(len(instance_types)) as executor:\n",
    "    results = executor.map(parallel_gen, [[m, i] for (m, i) in product(models, instance_types)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the Endpoints to save resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
